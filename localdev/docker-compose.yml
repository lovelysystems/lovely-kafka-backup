version: "3.9"

services:

  kafka-connect:
    image: ghcr.io/lovelysystems/lovely-kafka-backup:dev
    ports:
      - "8083:8083"
    volumes:
      - "./config/s3-config.json:/etc/kafka-connect/s3-config.json"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka:29092
      S3_CONNECTOR_NAME: loc-s3-sink-connector
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin

  kbackup:
    image: ghcr.io/lovelysystems/lovely-kafka-backup:dev
    # run bash and wait for user input
    tty: true
    environment:
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin

  kafka:
    image: apache/kafka:3.9.1
    container_name: localdev-kafka
    volumes:
      - "./volumes/kafka/data:/mnt/kafka/data"
    user: "0"
    ports:
      - "9092:9092"
    environment:
      # see config options here https://kafka.apache.org/documentation/#adminclientconfigs and prefix all with KAFKA_
      KAFKA_BROKER_ID: "1"
      KAFKA_ENABLE_KRAFT: "yes"
      ALLOW_PLAINTEXT_LISTENER: "yes"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,DOCKER:PLAINTEXT,HOST:PLAINTEXT'
      KAFKA_ADVERTISED_LISTENERS: 'DOCKER://kafka:29092,HOST://localhost:9092'
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:29093'
      KAFKA_LISTENERS: 'DOCKER://kafka:29092,CONTROLLER://kafka:29093,HOST://0.0.0.0:9092'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'DOCKER'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'

      # enable gzip compression (even if producer did not activate compression)
      KAFKA_COMPRESSION_TYPE: gzip

      KAFKA_LOG_DIR: /mnt/kafka/data
      KAFKA_LOG_RETENTION_MS: -1
      KAFKA_LOG_RETENTION_BYTES: -1

      # stream time is defined by the source instead of the actual ingestion time
      KAFKA_MESSAGE_TIMESTAMP_TYPE: CreateTime

      # we allow deletion of topics in this dev setup, might not be used in prod
      KAFKA_DELETE_TOPIC_ENABLE: "true"
      # allow auto generation of topics
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"

      # used for single kafka broker
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0

  # redpanda console (formerly kowl) https://github.com/redpanda-data/console
  kowl:
    image: docker.redpanda.com/redpandadata/console:v2.3.3
    ports:
      - "5001:5000"
    entrypoint: /bin/sh
    command: -c "echo \"$$CONSOLE_CONFIG_FILE\" > /tmp/config.yml; /app/console"
    environment:
      CONFIG_FILEPATH: /tmp/config.yml
      CONSOLE_CONFIG_FILE: |
        kafka:
          brokers: ["kafka:29092"]
        server:
          listenPort: 5000
        connect:
          enabled: true
          clusters:
            - name: connect  # Required field, will be used as identifier in the frontend
              url: http://kafka-connect:8083
    depends_on:
      - kafka

  minio:
    image: minio/minio:latest
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    volumes:
      - "./volumes/minio_data:/data"
    command: server /data  --console-address ":9001"
    healthcheck:
      test: [ "CMD", "mc", "ready", "local" ]
      interval: 5s
      timeout: 5s
      retries: 5

  ensure-bucket:
    image: minio/mc:latest
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
          mc alias set minio http://minio:9000 minioadmin minioadmin;
          mc mb minio/user-devices;"
